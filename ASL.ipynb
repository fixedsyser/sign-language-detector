{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from util import draw_landmarks_on_image, draw_letter_on_image\n",
    "from image_landmarker import ImageLandmarker\n",
    "from livestream_landmarker import LivestreamLandmarker\n",
    "import json\n",
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asl_dir = \"american-sign-language-letters.v1i.coco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dataset from zip\n",
    "import zipfile\n",
    "with zipfile.ZipFile(f\"{asl_dir}.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(asl_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_images = []\n",
    "\n",
    "with open(f'{asl_dir}/train/_annotations.coco.json') as file:\n",
    "    annotation_dict = json.load(file)\n",
    "\n",
    "\n",
    "image_lookup = {item[\"id\"]: item for item in annotation_dict[\"images\"]}\n",
    "for annotation in annotation_dict[\"annotations\"]:\n",
    "    image_id = annotation[\"image_id\"]\n",
    "\n",
    "    if image_id in image_lookup:\n",
    "        image = image_lookup[image_id]\n",
    "        \n",
    "        labeled_images.append([image_id, image['file_name'], annotation['category_id']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = {}\n",
    "for category in annotation_dict['categories']:\n",
    "    letters[category['id']] = category['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_detection_result(detection_result):\n",
    "    processed_data = []\n",
    "    for landmarks in detection_result.hand_landmarks:\n",
    "        # Extract x, y, z coordinates from each landmark\n",
    "        for landmark in landmarks:\n",
    "            coords = [landmark.x, landmark.y, landmark.z]\n",
    "            processed_data.append(coords)\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_add_image(X, Y, detector, image, category_id):\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image)\n",
    "    \n",
    "    detection_result = detector.detect(mp_image)\n",
    "    \n",
    "    # check for empty detection result\n",
    "    if detection_result.hand_landmarks != []:\n",
    "        X.append(process_detection_result(detection_result))\n",
    "        Y.append(category_id)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "try:\n",
    "    detector = ImageLandmarker()\n",
    "    for image in labeled_images:\n",
    "        filename = f\"{asl_dir}/train/\" + image[1]\n",
    "        \n",
    "        rgb_image = cv.cvtColor(cv.imread(filename), cv.COLOR_BGR2RGB)\n",
    "        flipped_image = cv.flip(rgb_image, 1) # flip to make it detect both hands equally\n",
    "        \n",
    "        X, Y = detect_and_add_image(X,Y, detector, rgb_image, image[2])\n",
    "        X, Y = detect_and_add_image(X,Y, detector, flipped_image, image[2])\n",
    "        \n",
    "finally: \n",
    "    detector.close()\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_flat, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ASL_prediction(detection_result):\n",
    "    letter_id = 0\n",
    "    try:\n",
    "        if detection_result.hand_landmarks != []:\n",
    "            processed_result = process_detection_result(detection_result)\n",
    "            X_flat = np.array(processed_result).reshape(1, -1)\n",
    "            letter_id = clf.predict(X_flat)[0]\n",
    "    except AttributeError:\n",
    "        # if no landmarks detected, detection_result does not have an attribute hand_landmarks\n",
    "        pass\n",
    "    return letters.get(letter_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cap = cv.VideoCapture(0)\n",
    "    detector = LivestreamLandmarker()\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        exit()\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        # if frame is read correctly ret is True\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "        detector.detect_async(mp_image)\n",
    "        landmarked_image = draw_landmarks_on_image(mp_image.numpy_view(), detector.result)\n",
    "        ASL_letter = get_ASL_prediction(detector.result)\n",
    "        annotated_image = draw_letter_on_image(landmarked_image, ASL_letter)\n",
    "        cv.imshow('frame', annotated_image)\n",
    "        # 1000/100 = 100 FPS\n",
    "        if cv.waitKey(100) == ord('q'):\n",
    "            break\n",
    "finally:    \n",
    "    detector.close()\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
